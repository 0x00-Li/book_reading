# 基于keepalived的LVS搭建

## 回顾

### 四层负载

四层负载，不涉及网络链接，和握手

### 七层负载

nginx是基于反向代理的七层负载，数据都会先链接到ngx



## 存在的隐患

### 问题分析

1. 负载均衡器挂掉，业务下线（单点故障）
2. 一台server挂掉后，部分用户可用（lvs还存在故障机器记录）

### 解决方案

单点故障解决方式：一变多，进行解决

1. 多个lvs，行不通ip不能重复
2. 多点：形式；主备，主主

### 主备解决

- 方向性
- 效率性

> 主备，主（单点->主备）从

**如何决定主挂了？**

备主动轮训

备被动观察



**如何确定server挂了？**

ping 不对检验3层网络是否通不通

访问一下验证http协议，返回是否200



**实现方案**

1. 修改LVS源码

2. 第三方实现方案
3. 人  => 相应慢，最不靠谱

**企业追求自动化！！！把人解放出去！！**

！！！！keepalived:解决单点故障，实现HA

#### keepalived

> 是一个通用工具，主要作为HA实现

1. 监控自己服务
2. master通告自己还活着，backup监听master状态，master挂了，一堆backup选举出新的master
3. 配置VIP，添加LVS配置；keepalived是有配置文件的
4. 对后端server进行健康检查



#### keepalived 搭建

> 结合之前的实验手册，保留node02,node03的配置，保证node01,node04为裸机

**清理node01**

ipvsadm -C 清理lvs

ifconfig down eth0:8

---

在node01，node04

`yum install keepalived ipvsadm -y`

编辑keepalived配置

`/etc/keepalived`

vrrp 虚拟路由冗余配置 

- state MASTER

